
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
           "http://www.w3.org/TR/REC-html40/loose.dtd">
<html class="jumbotron"><body class="container"><link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous"><link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap-theme.min.css" integrity="sha384-rHyoN1iRsVXV4nD0JutlnGaslCJuC7uwjduW9SVrLvRYooPp2bWYgmgJQIXwl/Sp" crossorigin="anonymous"><link href='http://fonts.googleapis.com/css?family=Roboto' rel='stylesheet' type='text/css'><style>
    img {     max-width: 100%;
    max-height: 40vh; } p { line-height: 1.5em; font-size: 18px !important; } * { color: #333333; } table hr { border-top: solid 2px #333333; } body {
      font-family: 'Roboto', sans-serif !important;
      font-size: 18px;
    }
  </style>
<title>footnote.html</title>
<table width="100%"><tr><td>
 <a href="index.html">HEAD</a></td><td align="right">
 <a href="docindex.html">PREVIOUS
</a></td></tr></table><hr /><h3>Footnotes:</h3>

</p><p>
<a id="tthFtNtAAB"></a><a href="chap1.html#tthFrefAAB"><sup>1</sup></a>Throughout this book, matrices
  and vectors in abstract multidimensional space are denoted by
  upright bold font. Vectors in physical three-dimensional space are
  instead denoted by italic bold font.
</p><p>
<a id="tthFtNtAAC"></a><a href="chap1.html#tthFrefAAC"><sup>2</sup></a>This
  problem with polynomial fitting is sometimes called Runge's
  phenomenon.
</p><p>
<a id="tthFtNtAAD"></a><a href="chap1.html#tthFrefAAD"><sup>3</sup></a>Sometimes called simply "orthogonal",
  the real version of "unitary".
</p><p>
<a id="tthFtNtAAE"></a><a href="chap1.html#tthFrefAAE"><sup>4</sup></a>A
  highly abbreviated outline of the SVD is as follows. The
  M&times;M matrix <b>S</b><sup>T</sup><b>S</b> is symmetric. Therefore it has
  real eigenvalues d<sub>i</sub><sup>2</sup> which because of its form are
  non-negative. Its eigenvectors <b><i>v</i></b><sub>i</sub>, satisfying
  <b>S</b><sup>T</sup><b>S</b><b><i>v</i></b><sub>i</sub>=d<sub>i</sub><sup>2</sup><b><i>v</i></b><sub>i</sub>, can be arranged into an
  orthonormal set in order of decreasing magnitude of d<sub>i</sub><sup>2</sup>. The M
  eigenvectors can be considered the columns of an orthonormal matrix
  <b>V</b>, which diagonalizes <b>S</b><sup>T</sup><b>S</b> so that
  <b>V</b><sup>T</sup><b>S</b><sup>T</sup><b>S</b><b>V</b> = <b>D</b><sup>2</sup>
  is an M&times;M non-negative, diagonal matrix with diagonal values
  d<sub>i</sub><sup>2</sup>. Since (<b>S</b><b>V</b>)<sup>T</sup> <b>S</b><b>V</b> is diagonal, the
  columns of the N&times;M matrix <b>SV</b> are orthogonal. Its
  columns corresponding to d<sub>i</sub>=0 are zero and are not useful to us.
  The useful columns corresponding to non-zero d<sub>i</sub> (i=1,...,L,
  say, L &#8804; M) can be normalized by dividing by d<sub>i</sub>. Then by
  appending N&#8722;L normalized column N-vectors that are orthogonal to
  all the previous ones, we can construct a complete N&times;N
  orthonormal matrix <b>U</b> = [<b>S</b><b>V</b><b>D</b><sup>&#8722;1</sup><sub>L</sub>,<b>U</b><sub>N&#8722;L</sub>]. Here <b>D</b><sup>&#8722;1</sup><sub>L</sub>
  denotes the M&times;L diagonal matrix with elements 1/d<sub>i</sub> and
  <b>U</b><sub>N&#8722;L</sub> denotes the appended extra columns. Now consider
  <b>U</b><b>D</b><b>V</b><sup>T</sup>. The appended <b>U</b><sub>N&#8722;L</sub> make zero
  contribution to this product because the lower rows of <b>D</b>
  which they multiply are always zero. The rest of the product is
  <b>S</b><b>V</b><b>D</b><sup>&#8722;1</sup><sub>L</sub> <b>D</b><sub>L</sub><b>V</b><sup>T</sup>=<b>S</b>. Therefore
  we have constructed the singular value decomposition
  <b>S</b>=<b>U</b><b>D</b><b>V</b><sup>T</sup>.
</p><p>
<a id="tthFtNtAAF"></a><a href="chap1.html#tthFrefAAF"><sup>5</sup></a>If M &gt;  N, the combination <b>D</b><b>D</b><sup>&#8722;1</sup>, which
arises from forming <b>S</b><b>S</b><sup>&#8722;1</sup> is not an M&times;M
identity matrix. Instead it has ones only at most for the first N of the
diagonal positions, and zeros thereafter. It is an N&times;N
identity matrix with extra zero rows and columns padding it out to
M&times;M. So the pseudo inverse is a funny kind of inverse which
works only one way.

</p><p>
If <b>S</b> is square and <em>nonsingular</em>, then the pseudo
inverse is exactly the same as the (normal) inverse.

</p><p>
If <b>S</b> were a <em>singular</em> square matrix, for example (and
possibly in other situations) then at least one of the original d<sub>j</sub>
would be zero. We usually consider the singular values (d<sub>j</sub>) to be
arranged in descending order of size; so that the zero values come at
the end. <b>D</b><sup>&#8722;1</sup> would then have an element 1/d<sub>j</sub> that is
<em>infinite</em>, and the formal manipulations would be
unjustified. What the pseudo-inverse does in these tricky cases is put
the value of the inverse 1/d<sub>j</sub> equal to zero instead of infinity. In
that case, once again, an incomplete identity matrix is produced, with
extra diagonal zeros at the end. And it actually doesn't
completely "work" as an inverse in either direction.

</p><p>
For those who know some linear algebra, what's happening is that the
pseudo-inverse projects vectors in the range of the original matrix
back into the complement of its nullspace.
</p><p>
<a id="tthFtNtAAG"></a><a href="chap1.html#tthFrefAAG"><sup>6</sup></a>See for example, <i>Numerical
    Recipes</i>, W H Press, B P Flannery, S A Teukolsky, and W T
  Vettering, Cambridge University Press (first edition, 1989)
  (henceforth cited simply as <i>Numerical Recipes</i>)
  Section 2.9.
</p><p>
<a id="tthFtNtAAH"></a><a href="chap1.html#tthFrefAAH"><sup>7</sup></a>by QR decomposition
</p><p>
<a id="tthFtNtAAI"></a><a href="chap1.html#tthFrefAAI"><sup>8</sup></a>This notation means the first N rows of the compound
  matrix consist of <b>S</b>, and the next N<sub>R</sub> rows are &#955;<b>R</b>.
</p><p>
<a id="tthFtNtAAJ"></a><a href="chap1.html#tthFrefAAJ"><sup>9</sup></a>This regularization is
  equivalent to what is sometimes called a "smoothing spline". In
  the limit of large smoothing parameter &#955;, the function f
  is a straight line (zero second derivative everywhere). In the limit
  of small &#955;, it is a cubic spline interpolation through all
  the values (x<sub>i</sub>,y<sub>i</sub>).
</p><p>
<a id="tthFtNtABA"></a><a href="chap1.html#tthFrefABA"><sup>10</sup></a>This topic and many others in data fitting is
  addressed for example in Siegmund Brandt (2014) <i>Data Analysis
    Statistical and Computational Methods for Scientists and
    Engineers</i>, Fourth Ed., Springer, New York.
</p><p>
<a id="tthFtNtABB"></a><a href="chap1.html#tthFrefABB"><sup>11</sup></a>Of course Fourier analysis is usually approached
  differently, as briefly discussed in the final chapter. We are here
  just using sine as an example function, in part because it is
  familiar.
</p><p>
<a id="tthFtNtABC"></a><a href="chap1.html#tthFrefABC"><sup>12</sup></a>There are lots of other
  correct but more verbose ways of doing it.
</p><p>
<a id="tthFtNtABD"></a><a href="chap2.html#tthFrefABD"><sup>13</sup></a>If f is independent of y, then we should use
  f(x<sub>n+1/2</sub>) where x<sub>n+1/2</sub>=(x<sub>n+1</sub>+x<sub>n</sub>)/2, and we then have a formula accurate to second-order
  for performing simple integration
  <br clear="all" /><table border="0" align="left" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap">&#8747;<sub>0</sub><sup>x<sub>n</sub></sup>f(x)dx=y<sub>n</sub>&#8722;y<sub>0</sub>=</td><td nowrap="nowrap" align="center">
<small>n&#8722;1</small><!--sup
--><br /><span class="largerstill">&#8721;<br />
</span><small>k=0</small>&nbsp;<br /></td><td nowrap="nowrap" align="center">
f(x<sub>k+1/2</sub>)(x<sub>k+1</sub>&#8722;x<sub>k</sub>)
</td></tr></table><br />. There are fancier, higher-order, ways
  to do integration, but this is by far the most straightforward.
</p><p>
<a id="tthFtNtABE"></a><a href="chap2.html#tthFrefABE"><sup>14</sup></a>The notation
  O(&#1013;<sup>n</sup>) denotes additional terms whose magnitude is
  proportional to a (usually small) parameter &#1013; raised to the
  power n or higher.
</p><p>
<a id="tthFtNtABF"></a><a href="chap2.html#tthFrefABF"><sup>15</sup></a>The proof is
  rather hard work. Here's an outline. Use notation F(&#948; x)=f(y(x<sub>n</sub>+&#948;x),&#948;x) to refer to values of the derivative
  function along the exact orbit. Suppose we compose <br clear="all" /><table border="0" align="left" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap">&#8710;y = (<sup>1</sup>/<sub>6</sub>F(0)+<sup>1</sup>/<sub>3</sub>F(</td><td nowrap="nowrap" align="center">
&#8710;
<div class="hrcomp"><hr noshade="noshade" size="1"/></div>2<br /></td><td nowrap="nowrap" align="center">
) +<sup>1</sup>/<sub>3</sub>F(</td><td nowrap="nowrap" align="center">
&#8710;
<div class="hrcomp"><hr noshade="noshade" size="1"/></div>2<br /></td><td nowrap="nowrap" align="center">
)+<sup>1</sup>/<sub>6</sub>F(&#8710;))&#8710;
</td></tr></table><br />. This is
  the form corresponding to eqs.&nbsp;(<a href="chap2.html#ode17a">2.16</a>) and (<a href="chap2.html#ode18">2.17</a>),
  but using the exact f on the orbit, rather than the intermediate
  f<sup>(n)</sup> estimates. By substituting from eq.&nbsp;(<a href="chap2.html#ode12">2.11</a>) it is
  easy but tedious to show that this &#8710;y is equal to y(x<sub>n</sub>+&#8710;) &#8722; y<sub>n</sub>+O(&#8710;<sup>5</sup>); that is, it is an accurate representation of the
  y-step to fourth-order. Actually it is instructive to realize that
  the symmetry of the &#948;x positions, 0, <br clear="all" /><table border="0" align="left" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap"></td><td nowrap="nowrap" align="center">
&#8710;
<div class="hrcomp"><hr noshade="noshade" size="1"/></div>2<br /></td><td nowrap="nowrap" align="center">

</td></tr></table><br />, and
  &#8710; ensures that all even order errors in this &#8710;y are
  zero while the first-order error is zero because the coefficients sum
  to unity. The factor of 2 difference between the center and the end
  coefficients is the choice that makes the third-order error zero. In
  itself this has not proved the scheme to be fourth-order accurate,
  because there are non-zero differences approximately proportional to
  <br clear="all" /><table border="0" align="left" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap"></td><td nowrap="nowrap" align="center">
&#8706;f
<div class="hrcomp"><hr noshade="noshade" size="1"/></div>&#8706;y<br /></td><td nowrap="nowrap" align="center">

</td></tr></table><br /> between the f values and the F values:
  <br clear="all" /><table border="0" align="left" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap">f<sup>(1)</sup>&#8722;F(</td><td nowrap="nowrap" align="center">
&#8710;
<div class="hrcomp"><hr noshade="noshade" size="1"/></div>2<br /></td><td nowrap="nowrap" align="center">
)=</td><td nowrap="nowrap" align="center">
&#8706;f
<div class="hrcomp"><hr noshade="noshade" size="1"/></div>&#8706; y<br /></td><td nowrap="nowrap" align="center">
(y<sup>(1)</sup>&#8722;y(</td><td nowrap="nowrap" align="center">
&#8710;
<div class="hrcomp"><hr noshade="noshade" size="1"/></div>2<br /></td><td nowrap="nowrap" align="center">
))
</td></tr></table><br />, <br clear="all" /><table border="0" align="left" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap">f<sup>(2)</sup>&#8722;F(</td><td nowrap="nowrap" align="center">
&#8710;
<div class="hrcomp"><hr noshade="noshade" size="1"/></div>2<br /></td><td nowrap="nowrap" align="center">
)=</td><td nowrap="nowrap" align="center">
&#8706;f
<div class="hrcomp"><hr noshade="noshade" size="1"/></div>&#8706;y<br /></td><td nowrap="nowrap" align="center">
(y<sup>(2)</sup>&#8722;y(</td><td nowrap="nowrap" align="center">
&#8710;
<div class="hrcomp"><hr noshade="noshade" size="1"/></div>2<br /></td><td nowrap="nowrap" align="center">
))
</td></tr></table><br />,
  and <br clear="all" /><table border="0" align="left" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap">f<sup>(3)</sup>&#8722;F(&#8710;)=</td><td nowrap="nowrap" align="center">
&#8706;f
<div class="hrcomp"><hr noshade="noshade" size="1"/></div>&#8706; y<br /></td><td nowrap="nowrap" align="center">
(y<sup>(3)</sup>&#8722;y(&#8710;))
</td></tr></table><br />. (Because of the order of the
  y-differences one can quickly see that <br clear="all" /><table border="0" align="left" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap"></td><td nowrap="nowrap" align="center">
&#8706;<sup>2</sup>
<div class="hrcomp"><hr noshade="noshade" size="1"/></div>&#8706;y<sup>2</sup><br /></td><td nowrap="nowrap" align="center">

</td></tr></table><br />
  terms don't need to be kept.) The successive differences
  such as <br clear="all" /><table border="0" align="left" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap">(y<sup>(1)</sup>&#8722;y(</td><td nowrap="nowrap" align="center">
&#8710;
<div class="hrcomp"><hr noshade="noshade" size="1"/></div>2<br /></td><td nowrap="nowrap" align="center">
))
</td></tr></table><br /> can be expressed in terms of
  the Taylor expansion eq.&nbsp;(<a href="chap2.html#ode13">2.12</a>), and then the
  f-differences are gathered in the combination of eq.&nbsp;  (<a href="chap2.html#ode18">2.17</a>): <sup>1</sup>/<sub>6</sub>,<sup>1</sup>/<sub>3</sub>,<sup>1</sup>/<sub>3</sub>,<sup>1</sup>/<sub>6</sub>. One can
  then evaluate the <br clear="all" /><table border="0" align="left" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap"></td><td nowrap="nowrap" align="center">
&#8706;f
<div class="hrcomp"><hr noshade="noshade" size="1"/></div>&#8706;y<br /></td><td nowrap="nowrap" align="center">

</td></tr></table><br /> terms and demonstrate that they cancel to fourth
  order.

</p><p>
<a id="tthFtNtABG"></a><a href="chap3.html#tthFrefABG"><sup>16</sup></a>A more general form of bisection in which the
  interval is divided in two <em>unequal</em> parts weighted by the
  value of the function, s<sub>n</sub>=[f(s<sub>l</sub>)s<sub>u</sub>&#8722;f(s<sub>u</sub>)s<sub>l</sub>]/[f(s<sub>l</sub>)&#8722;f(s<sub>u</sub>)]
  has comparable robustness, requires no additional function
  evaluations per step but a couple of extra multiplications, and
  converges quicker than plain bisection except in special cases. This
  is sometimes called the "false-position" root-finding method. It
  is generally possible to detect automatically when one of those
  slowly converging special cases is encountered and take additional
  measures.
</p><p>
<a id="tthFtNtABH"></a><a href="chap3.html#tthFrefABH"><sup>17</sup></a>A shorthand way to remember the result
  for an order N derivative is that the numerator is the sum of the
  neighboring y values times the coefficients of a binomial
  expansion to the power N, and the denominator is &#8710;x<sup>N</sup>.
</p><p>
<a id="tthFtNtABI"></a><a href="chap3.html#tthFrefABI"><sup>18</sup></a>An alternative
  approach to implementing boundary conditions is to regard the
  boundary positions as outside and not operated upon by the
  difference matrix. Then its indices runs only from 2 to N&#8722;1, and
  it has dimensions (N&#8722;2)&times;(N&#8722;2). For Dirichlet conditions, the
  term in the difference stencils of positions 2 and N&#8722;1 that
  contains the boundary value is moved into the right-hand-side source
  vector. Generically the matrix equation is then
<br clear="all" /><table border="0" width="100%"><tr><td>
<table align="center" cellspacing="0"  cellpadding="2"><tr><td nowrap="nowrap" align="center">
 </td><td align="left" class="cl">&#x239B;<br />&#x239C;<br />&#x239C;<br />&#x239C;<br />
&#x239C;<br />&#x239C;<br />&#x239C;<br />&#x239D;
 </td><td nowrap="nowrap" align="center">
<table class="tabular">
<tr><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
&#8722;2 </td></tr></table></td><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
1 </td></tr></table></td><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
0 </td></tr></table></td><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
0 </td></tr></table></td><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
0 </td></tr></table></td></tr>
<tr><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
<sup><big>&#183;</big></sup>&#183;<sub><big>&#183;</big></sub></td></tr></table></td><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
<sup><big>&#183;</big></sup>&#183;<sub><big>&#183;</big></sub></td></tr></table></td><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
<sup><big>&#183;</big></sup>&#183;<sub><big>&#183;</big></sub></td></tr></table></td><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
0</td></tr></table></td><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
0</td></tr></table></td></tr>
<tr><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
0 </td></tr></table></td><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
1 </td></tr></table></td><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
&#8722;2 </td></tr></table></td><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
1 </td></tr></table></td><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
0</td></tr></table></td></tr>
<tr><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
0</td></tr></table></td><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
0 </td></tr></table></td><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
<sup><big>&#183;</big></sup>&#183;<sub><big>&#183;</big></sub></td></tr></table></td><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
<sup><big>&#183;</big></sup>&#183;<sub><big>&#183;</big></sub></td></tr></table></td><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
<sup><big>&#183;</big></sup>&#183;<sub><big>&#183;</big></sub></td></tr></table></td></tr>
<tr><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
0</td></tr></table></td><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
0 </td></tr></table></td><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
0 </td></tr></table></td><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
1 </td></tr></table></td><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
&#8722;2 </td></tr></table></td></tr></table>
</td><td nowrap="nowrap" align="center">
 </td><td align="left" class="cl">&#x239E;<br />&#x239F;<br />&#x239F;<br />&#x239F;<br />
&#x239F;<br />&#x239F;<br />&#x239F;<br />&#x23A0;
</td><td nowrap="nowrap" align="center">
</td><td align="left" class="cl">&#x239B;<br />&#x239C;<br />&#x239C;<br />&#x239C;<br />
&#x239C;<br />&#x239C;<br />&#x239C;<br />&#x239D;
 </td><td nowrap="nowrap" align="center">
<table class="tabular">
<tr><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
y<sub>2</sub></td></tr></table></td></tr>
<tr><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
:</td></tr></table></td></tr>
<tr><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
y<sub>n</sub></td></tr></table></td></tr>
<tr><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
:</td></tr></table></td></tr>
<tr><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
y<sub>N&#8722;1</sub></td></tr></table></td></tr></table>
</td><td align="left" class="cl">&#x239E;<br />&#x239F;<br />&#x239F;<br />&#x239F;<br />
&#x239F;<br />&#x239F;<br />&#x239F;<br />&#x23A0;
</td><td nowrap="nowrap" align="center">
 = </td><td align="left" class="cl">&#x239B;<br />&#x239C;<br />&#x239C;<br />&#x239C;<br />
&#x239C;<br />&#x239C;<br />&#x239C;<br />&#x239D;
 </td><td nowrap="nowrap" align="center">
<table class="tabular">
<tr><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
g<sub>2</sub>&#8710;x<sup>2</sup>&#8722;y<sub>L</sub> </td></tr></table></td></tr>
<tr><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
:</td></tr></table></td></tr>
<tr><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
g<sub>n</sub>&#8710;x<sup>2</sup></td></tr></table></td></tr>
<tr><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
:</td></tr></table></td></tr>
<tr><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
g<sub>N&#8722;1</sub>&#8710;x<sup>2</sup>&#8722;y<sub>R</sub></td></tr></table></td></tr></table>
</td><td align="left" class="cl">&#x239E;<br />&#x239F;<br />&#x239F;<br />&#x239F;<br />
&#x239F;<br />&#x239F;<br />&#x239F;<br />&#x23A0;
</td><td nowrap="nowrap" align="center">
.</td></tr></table>
</td></tr></table>


This form keeps the matrix symmetric, which is advantageous for some
inversion algorithms.

</p><p>
<a id="tthFtNtABJ"></a><a href="chap3.html#tthFrefABJ"><sup>19</sup></a>In some
  circumstances one can deliberately choose the mesh so as to put the
  boundary at x<sub>3/2</sub>.  Then the implementation represented by eq.&nbsp;  (3.15)   does put the value at the correct place. This mesh choice is
  appropriate if the boundary condition is known to be of purely
  derivative form. It then lends itself to the alternative approach of
  the previous note, excluding the boundary from <b>D</b>.  The top
  left coefficient becomes D<sub>22</sub>=&#8722;1, and &#8710;x&nbsp;dy/dx&#124;<sub>L</sub> is
  added to the source vector, to implement the boundary
  condition. Mixed boundary conditions are not handled so easily like
  this, which is why a second-order accurate form with the boundary at
  x<sub>1</sub> has been given.
</p><p>
<a id="tthFtNtACA"></a><a href="chap3.html#tthFrefACA"><sup>20</sup></a>The error in the
  first derivative y&#8242; is approximately y"<sub>2</sub>.<sup>1</sup>/<sub>2</sub>&#8710;x,
  first-order in &#8710;x, but the error in &#8710;y is
  second-order in &#8710;x giving first order accuracy.
</p><p>
<a id="tthFtNtACB"></a><a href="chap3.html#tthFrefACB"><sup>21</sup></a>With periodic boundary conditions the homogeneous
  equation (<br clear="all" /><table border="0" align="left" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap"></td><td nowrap="nowrap" align="center">
d<sup>2</sup>y
<div class="hrcomp"><hr noshade="noshade" size="1"/></div>dx<sup>2</sup><br /></td><td nowrap="nowrap" align="center">
=0
</td></tr></table><br />) is satisfied by any constant y. An
  additional condition must therefore be applied to make the solution
  unique.  Moreover, there exists no solution of the differential
  equation with continuous derivative unless &#8747;g dx=0. These
  requirements are reflected in the fact that the matrix of this
  system is singular. If (<a href="http://silas.psfc.mit.edu/22.15/lectures/chap3.htmlpt18">3.19</a>) is solved by
  pseudo-inverse, it gives the solution having zero mean: <br clear="all" /><table border="0" align="left" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap"></td><td nowrap="nowrap" align="center">
<span class="largerstill">&#8721;<br />
</span></td><td nowrap="nowrap">y<sub>n</sub>/N=0
</td></tr></table><br />, using as right-hand-side instead of &#8710;x<sup>2</sup><b>g</b>
  the quantity <br clear="all" /><table border="0" align="left" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap">&#8710;x<sup>2</sup>(<b>g</b>&#8722;</td><td nowrap="nowrap" align="center">
<span class="largerstill">&#8721;<br />
</span></td><td nowrap="nowrap">g<sub>n</sub> /N)
</td></tr></table><br />.
</p><p>
<a id="tthFtNtACC"></a><a href="chap3.html#tthFrefACC"><sup>22</sup></a>On a structured mesh, a
  finite volume method is identical to the finite difference method
  provided this conservative differencing is used.
</p><p>
<a id="tthFtNtACD"></a><a href="chap4.html#tthFrefACD"><sup>23</sup></a>The subscript q on &#961;<sub>q</sub>
  reminds us this is charge density, not mass density &#961; here.
</p><p>
<a id="tthFtNtACE"></a><a href="chap4.html#tthFrefACE"><sup>24</sup></a>Vector dependent variable problems are hyperbolic if the
matrix of the coefficients of their differentials is diagonizable with
real eigenvalues, as we'll see later.
</p><p>
<a id="tthFtNtACF"></a><a href="chap4.html#tthFrefACF"><sup>25</sup></a>Constructed with the distmesh routines from <a href="http://persson.berkeley.edu/distmesh/"><tt>http://persson.berkeley.edu/distmesh/</tt></a>
</p><p>
<a id="tthFtNtACG"></a><a href="chap4.html#tthFrefACG"><sup>26</sup></a>For object-oriented purists, this could
  be a "method".
</p><p>
<a id="tthFtNtACH"></a><a href="chap5.html#tthFrefACH"><sup>27</sup></a>In effect, we linearize about an exact solution of
  the equations and the &#968; we then analyse is the (presumed small)
  difference between the solution we obtain and the exact solution. In
  the text we avoid encumbrance of the notation by not drawing
  explicit attention to this fact.
</p><p>
<a id="tthFtNtACI"></a><a href="chap5.html#tthFrefACI"><sup>28</sup></a>The Nyquist limit.
</p><p>
<a id="tthFtNtACJ"></a><a href="chap5.html#tthFrefACJ"><sup>29</sup></a>Or, for example, an LU
  decomposition.
</p><p>
<a id="tthFtNtADA"></a><a href="chap5.html#tthFrefADA"><sup>30</sup></a>See for example
  <em>Numerical Recipes</em> section 2.6
</p><p>
<a id="tthFtNtADB"></a><a href="chap5.html#tthFrefADB"><sup>31</sup></a>Octave and
  Matlab have a simple built-in function to do reordering, called <tt>reshape()</tt>.
</p><p>
<a id="tthFtNtADC"></a><a href="chap5.html#tthFrefADC"><sup>32</sup></a>and of LU decomposition and backsubstitution
</p><p>
<a id="tthFtNtADD"></a><a href="chap5.html#tthFrefADD"><sup>33</sup></a>We
  could alternatively have used integral positions and the second
  order scheme of eq.&nbsp;<a href="http://silas.psfc.mit.edu/22.15/lectures/chap3.htmlpt15">3.16</a>)
</p><p>
<a id="tthFtNtADE"></a><a href="chap6.html#tthFrefADE"><sup>34</sup></a>Removing the
  (first-order) time derivative changes the classification of the equation
  because it is no longer a differential equation in t at all.
</p><p>
<a id="tthFtNtADF"></a><a href="chap6.html#tthFrefADF"><sup>35</sup></a>Jacobi's method actually can
  be used to solve a rather general matrix equation
  <b>B</b>&#968;=<b>s</b>, and is implemented as
  &#968;<sup>(n+1)</sup>=<b>D</b><sup>&#8722;1</sup>(<b>s</b>&#8722;<b>R</b>&#968;<sup>(n)</sup>), where
  <b>D</b> is the diagonal part of <b>B</b> and
  <b>R</b>=<b>B</b>&#8722;<b>D</b> is the rest. Its convergence is guaranteed
  if <b>B</b> is <em>diagonally dominant</em>, meaning that the
  absolute value of the diagonal term exceeds the sum of the absolute
  values of all the other coefficients of the corresponding
  row.
</p><p>
<a id="tthFtNtADG"></a><a href="chap6.html#tthFrefADG"><sup>36</sup></a>For the matrix expert, the advancing
  matrix is then explicitly "two-cyclic, and consistently ordered".
</p><p>
<a id="tthFtNtADH"></a><a href="chap6.html#tthFrefADH"><sup>37</sup></a>A Fourier treatment is not rigorously
  justified in general, but serves to illustrate simply the most
  important characteristics.
</p><p>
<a id="tthFtNtADI"></a><a href="chap6.html#tthFrefADI"><sup>38</sup></a>See the enrichment section
    for an outline if you are
  interested. G D Smith <em>Numerical Soution of Partial
    Differential Equations</em>, Oxford University Press, 1985, p275ff
  gives an accessible detailed treatment.
</p><p>
<a id="tthFtNtADJ"></a><a href="chap6.html#tthFrefADJ"><sup>39</sup></a>If we apply the boundary
  conditions, then the <em>eigenmode</em> is actually
  sin(jp&#960;/N<sub>x</sub>)sin(kq&#960;/N<sub>y</sub>) but the complex Von Neumann
  analysis gives the same result.
</p><p>
<a id="tthFtNtAEA"></a><a href="chap6.html#tthFrefAEA"><sup>40</sup></a>In
fact, if N<sub>x</sub>=N<sub>y</sub> and &#8710;x=&#8710;y, then M=N<sub>x</sub>, or
alternatively if &#8710;y &gt;&gt; &#8710;x, and N<sub>x</sub> is not far smaller
than N<sub>y</sub>, then M &#8776; N<sub>x</sub>.
</p><p>
<a id="tthFtNtAEB"></a><a href="chap6.html#tthFrefAEB"><sup>41</sup></a>the
difference between the "converged" iterative &#968;(0) and the
analytic &#968;(0) normalized to the analytic value.
</p><p>
<a id="tthFtNtAEC"></a><a href="chap7.html#tthFrefAEC"><sup>42</sup></a>If the Jacobian is position-dependent, then the
  modes are only approximately uncoupled, because our analysis is
  effectively assuming that <b>J</b> and &#8706;/&#8706;x
  commute, which is not exact if <b>J</b> is spatially-varying.  The
  stability analysis is then local, and only approximate. But in any
  case Von Neumann stability analysis is only approximate in
  non-uniform cases.
</p><p>
<a id="tthFtNtAED"></a><a href="chap7.html#tthFrefAED"><sup>43</sup></a>provided the eigenvectors
  are linearly independent
</p><p>
<a id="tthFtNtAEE"></a><a href="chap7.html#tthFrefAEE"><sup>44</sup></a>Although this can be proved, it
  is complicated.
</p><p>
<a id="tthFtNtAEF"></a><a href="chap8.html#tthFrefAEF"><sup>45</sup></a>There is considerable subtlety
  in the question "how abruptly". After all any velocity change
  really takes a finite time and involves an acceleration. Why isn't
  it included in <b><i>a</i></b>? For present purposes we'll just finesse
  this question by saying that the source contains any velocity
  changes that are not included in the acceleration.
</p><p>
<a id="tthFtNtAEG"></a><a href="chap8.html#tthFrefAEG"><sup>46</sup></a>(not multiple dependent
  variables that have to be arranged into a vector representation
  whose eigenvalue might not be real)
</p><p>
<a id="tthFtNtAEH"></a><a href="chap9.html#tthFrefAEH"><sup>47</sup></a>The transport of
  radiation, of <em>photons</em>, can also be treated in this
  way, but their treatment has to be expressed in terms of energy (or
  momentum) rather than speed, since all photons travel at the same
  speed.
</p><p>
<a id="tthFtNtAEI"></a><a href="chap9.html#tthFrefAEI"><sup>48</sup></a>Also there may be other spontaneous decays or
  fissions (delayed neutrons) but we'll ignore them for now.
</p><p>
<a id="tthFtNtAEJ"></a><a href="chap9.html#tthFrefAEJ"><sup>49</sup></a>Most reactor physics texts express the velocity
  distribution differently, in terms of flux density &#981; &#8801; v f,
  as the dependent variable. To retain the more general relevance to
  solving Boltzmann's equation, we here keep f as the dependent
  variable. The result is still equivalent to standard reactor physics
  equations.
</p><p>
<a id="tthFtNtAFA"></a><a href="chap9.html#tthFrefAFA"><sup>50</sup></a>Although there we might have to include
  self-collisions.
</p><p>
<a id="tthFtNtAFB"></a><a href="chap9.html#tthFrefAFB"><sup>51</sup></a>In practice delayed neutrons introduce a
  severe complication.
</p><p>
<a id="tthFtNtAFC"></a><a href="chap9.html#tthFrefAFC"><sup>52</sup></a>Computational size reduction, retaining spatial
  dependence, might call for a very small number of speed
  groups. Perhaps even a single group N<sub>G</sub>=1. Then the neutron
  transport is reduced to a single diffusion equation.
</p><p>
<a id="tthFtNtAFD"></a><a href="chap9.html#tthFrefAFD"><sup>53</sup></a>And the boundary conditions are also homogeneous. Of
  course "homogeneous" does not here mean uniform in space; it means
  having no constant terms.
</p><p>
<a id="tthFtNtAFE"></a><a href="chap9.html#tthFrefAFE"><sup>54</sup></a>Strictly speaking,
  the inverse of the eigenvalues of the matrix
  (&#957;&#931;<sub>f</sub><b>V</b>)<sup>&#8722;1</sup>(&#8722;<b>L</b>+&#931;<sub>t</sub><b>V</b>&#8722;&#931;<sub>s</sub><b>V</b>).
</p><p>
<a id="tthFtNtAFF"></a><a href="chap9.html#tthFrefAFF"><sup>55</sup></a>A generalized eigenvalue is the solution
  to (<b>A</b>&#8722;&#955;<b>B</b>)<b>v</b>=0 where both <b>A</b> and
  <b>B</b> are general matrices.
</p><p>
<a id="tthFtNtAFG"></a><a href="chap9.html#tthFrefAFG"><sup>56</sup></a>Actually if it were the largest eigenvalue of
  <b>M</b>, for a single group or diagonal <b>G</b> we could
  directly use the "power method", which is eq.&nbsp;<a href="chap9.html#eigschem">9.16</a> with
  the F-indices (n, n+1) exchanged. However, because we want the
  smallest eigenvalue 1/k, we must effectively invert <b>M</b>
  (which requires interior iteration) because <b>M</b> is never
  diagonal.
</p><p>
<a id="tthFtNtAFH"></a><a href="chap9.html#tthFrefAFH"><sup>57</sup></a>e.g.&nbsp;  SOR
</p><p>
<a id="tthFtNtAFI"></a><a href="chap9.html#tthFrefAFI"><sup>58</sup></a>See e.g.&nbsp;<em>Applied
    Reactor Physics</em> Alain H&#233;bert, Presses internationales
  Polytechnique, www.polymtl.ca, (2009). Actually many other choices
  of weighting will work as well, not just
  (<b>G</b><b>F</b><sup>(n+1)</sup>)<sup>T</sup>.
</p><p>
<a id="tthFtNtAFJ"></a><a href="chap9.html#tthFrefAFJ"><sup>59</sup></a>The zeroes in the non-diagonal matrices arise because
  scatterings hardly ever move neutrons to higher energy or reduce the
  energy by more than one group, and fissions give rise only to
  energetic neutrons. The values given are roughly appropriate for a
  pressurized water reactor.
</p><p>
<a id="tthFtNtAGA"></a><a href="chap9.html#tthFrefAGA"><sup>60</sup></a>In reactor physics B is called
  the "Buckling".
</p><p>
<a id="tthFtNtAGB"></a><a href="chap10.html#tthFrefAGB"><sup>61</sup></a>Alder and Wainwright, "Phase transition for a hard
  sphere system", J. Chem. Phys. 27, 1208-1209, (1957). Liquid
  behavior is an important phenomenon for which Molecular Dynamics is
  useful.
</p><p>
<a id="tthFtNtAGC"></a><a href="chap10.html#tthFrefAGC"><sup>62</sup></a>For fixed &#8710;t, the Verlet and leap-frog
  schemes are equivalent, with the identification
  <b><i>v</i></b><sub>n</sub>=(<b><i>v</i></b><sub>n&#8722;1/2</sub>+<b><i>v</i></b><sub>n+1/2</sub>)/2. The Verlet scheme,
  implemented in terms of velocity as in eq.&nbsp;(<a href="chap10.html#Verlet">10.1</a>),
  requires more storage or more acceleration evaluations: because two
  values of <b><i>a</i></b> are needed. It can be implemented in terms of
  the position advance alone as
  <b><i>x</i></b><sub>n+1</sub>=2<b><i>x</i></b><sub>n</sub>&#8722;<b><i>x</i></b><sub>n&#8722;1</sub> +<b><i>a</i></b>&#8710;t<sup>2</sup>, which
  requires the same storage as leap-frog.
</p><p>
<a id="tthFtNtAGD"></a><a href="chap10.html#tthFrefAGD"><sup>63</sup></a>Since the step cost for a neighboring
  domain of size  &#8733; N<sub>l</sub> is  &#8733; N<sub>p</sub>N<sub>l</sub><sup>3</sup>, and the step
  cost for the neighbor update is  &#8733; N<sub>p</sub><sup>2</sup>/N<sub>l</sub>, a formal
  optimum occurs when these are equal N<sub>l</sub> &#8733; N<sub>p</sub><sup>1/4</sup>. So
  formally, the per-step cost of this N<sub>l</sub>-optimized algorithm would
  be  &#8733; N<sub>p</sub>N<sub>p</sub><sup>3/4</sup>: slightly better than N<sub>p</sub><sup>2</sup>.
</p><p>
<a id="tthFtNtAGE"></a><a href="chap10.html#tthFrefAGE"><sup>64</sup></a>See
  for example C K Birdsall and A B Langdon (1991)
  <i>Plasma Physics via Computer Simulation</i>, IOP
  Publishing, Bristol; or R W Hockney and J W Eastwood (1988)
  <i>Computer Simulation using Particles</i>, Taylor and
  Francis, New York
</p><p>
<a id="tthFtNtAGF"></a><a href="chap10.html#tthFrefAGF"><sup>65</sup></a>See for example the SOR estimates.
</p><p>
<a id="tthFtNtAGG"></a><a href="chap11.html#tthFrefAGG"><sup>66</sup></a>Siegmund Brandt
  (2014) <i>Data Analysis Statistical and Computational Methods for
    Scientists and Engineers</i>, Fourth Ed., Springer, New York, gives a
  much more expansive introduction to statistics and Monte Carlo
  techniques.
</p><p>
<a id="tthFtNtAGH"></a><a href="chap11.html#tthFrefAGH"><sup>67</sup></a>Statisticians use the
  generic word "sample" to refer to the particular result of a
  single test or measurement.
</p><p>
<a id="tthFtNtAGI"></a><a href="chap11.html#tthFrefAGI"><sup>68</sup></a>Division by the factor N&#8722;1
  rather than N makes this formula an unbiassed estimate of the
  distribution variance. One way to understand this is to recognize
  that the number of degrees of freedom of <br clear="all" /><table border="0" align="left" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap"></td><td nowrap="nowrap" align="center">
<small>N</small><!--sup
--><br /><span class="largerstill">&#8721;<br />
</span><small>1</small>&nbsp;<br /></td><td nowrap="nowrap" align="center">
(v<sub>i</sub>&#8722;&#956;<sub>N</sub>)<sup>2</sup>
</td></tr></table><br /> is
  N&#8722;1, not N. Using N&#8722;1 is sometimes called "Bessel's
  correction".
</p><p>
<a id="tthFtNtAGJ"></a><a href="chap11.html#tthFrefAGJ"><sup>69</sup></a>Often called the "expectation" of
  v
</p><p>
<a id="tthFtNtAHA"></a><a href="chap11.html#tthFrefAHA"><sup>70</sup></a><b>Central Limit Theorem</b>. It is not
  straightforward to prove that the distribution becomes Gaussian. But
  it is fairly easy to show that the variance of the sample mean is
  the variance of the distribution divided by N. From the definition
  of &#956;<sub>N</sub> one can immediately deduce
  that
<br clear="all" /><table border="0" width="100%"><tr><td>
<table align="center" cellspacing="0"  cellpadding="2"><tr><td nowrap="nowrap" align="center">
(&#956;<sub>N</sub>&#8722;&#956;)<sup>2</sup>=</td><td align="left" class="cl">&#x239B;<br />&#x239D;
</td><td nowrap="nowrap" align="center">
1
<div class="hrcomp"><hr noshade="noshade" size="1"/></div>N<br /></td><td nowrap="nowrap" align="center">
</td><td nowrap="nowrap" align="center">
<small>N</small><!--sup
--><br /><span class="largerstill">&#8721;<br />
</span><small>1</small>&nbsp;<br /></td><td nowrap="nowrap" align="center">
(v<sub>i</sub>&#8722;&#956;)</td><td align="left" class="cl">&#x239E;<br />&#x23A0;
</td><td nowrap="nowrap" align="center">
<small>2</small><!--sup
--><br /><br />
<small></small>&nbsp;<br /></td><td nowrap="nowrap" align="center">
=</td><td nowrap="nowrap" align="center">
1
<div class="hrcomp"><hr noshade="noshade" size="1"/></div>N<sup>2</sup><br /></td><td nowrap="nowrap" align="center">
</td><td nowrap="nowrap" align="center">
<small>N</small><!--sup
--><br /><span class="largerstill">&#8721;<br />
</span><small>i,j</small>&nbsp;<br /></td><td nowrap="nowrap" align="center">
(v<sub>i</sub>&#8722;&#956;)(v<sub>j</sub>&#8722;&#956;). </td></tr></table>
</td></tr></table>

 Take the expectation
  &#9001;... &#9002; of this quantity to obtain the variance of
  the distribution of sample means:

<br clear="all" /><table border="0" width="100%"><tr><td>
<table align="center" cellspacing="0"  cellpadding="2"><tr><td nowrap="nowrap" align="center">
&#9001;(&#956;<sub>N</sub>&#8722;&#956;)<sup>2</sup>&#9002; = </td><td nowrap="nowrap" align="center">
1
<div class="hrcomp"><hr noshade="noshade" size="1"/></div>N<sup>2</sup><br /></td><td nowrap="nowrap" align="center">
</td><td nowrap="nowrap" align="center">
<small>N</small><!--sup
--><br /><span class="largerstill">&#8721;<br />
</span><small>i,j</small>&nbsp;<br /></td><td nowrap="nowrap" align="center">
&#9001;(v<sub>i</sub>&#8722;&#956;)(v<sub>j</sub>&#8722;&#956;)&#9002; = </td><td nowrap="nowrap" align="center">
1
<div class="hrcomp"><hr noshade="noshade" size="1"/></div>N<sup>2</sup><br /></td><td nowrap="nowrap" align="center">
</td><td nowrap="nowrap" align="center">
<small>N</small><!--sup
--><br /><span class="largerstill">&#8721;<br />
</span><small>i</small>&nbsp;<br /></td><td nowrap="nowrap" align="center">
&#9001;(v<sub>i</sub>&#8722;&#956;)<sup>2</sup>&#9002; = </td><td nowrap="nowrap" align="center">
S<sup>2</sup>
<div class="hrcomp"><hr noshade="noshade" size="1"/></div>N<br /></td><td nowrap="nowrap" align="center">
. </td></tr></table>
</td></tr></table>

 The first
  equality, taking the expectation inside the sum, is a simple
  property of taking the expectation: the expectation of a sum is the
  sum of the expectations. The second equality uses the fact that
  &#9001;(v<sub>i</sub>&#8722;&#956;)(v<sub>j</sub>&#8722;&#956;)&#9002; = 0 for i &#8800; j because the
  quantities (v<sub>i</sub>&#8722;&#956;) are statistically independent and have zero
  mean. That is sufficient to yield the required result. Our estimate
  for the distribution variance is S<sup>2</sup>=S<sub>N</sub><sup>2</sup>. So the unbiassed
  estimate for the variance of &#956;<sub>N</sub> is
  &#9001;(&#956;<sub>N</sub>&#8722;&#956;)<sup>2</sup>&#9002; = S<sub>N</sub><sup>2</sup>/N. The standard error is the
  square root of this quantity.
</p><p>
<a id="tthFtNtAHB"></a><a href="chap11.html#tthFrefAHB"><sup>71</sup></a>An un-normalized
  Gaussian distribution has three, including the height.
</p><p>
<a id="tthFtNtAHC"></a><a href="chap11.html#tthFrefAHC"><sup>72</sup></a>Linear interpolation is then
  equivalent to representing p<sub>v</sub> as a histogram. So adequate
  resolution may require a fairly large number N<sub>t</sub>.
</p><p>
<a id="tthFtNtAHD"></a><a href="chap11.html#tthFrefAHD"><sup>73</sup></a><b>Quiet
    start and quasi-random selection.</b> When starting a
  particle-in-cell simulation, the initial positions of the particles
  might be chosen using random numbers to decide their
  location. However, they then will have density fluctuations of
  various wavelengths that in plasmas may be <em>bigger</em> than are
  present after running the simulation for many steps. The reason for
  this discrepancy is that the feedback effect of the self-consistent
  electric potential tends to smooth out density fluctuations, so that
  in the fully developed simulation the noise level is lower than
  purely random. A simple way of saying the same thing is that
  individual particles <em>repel</em> others of the same type,
  preventing clumping of the particles. It is therefore often
  physically reasonable to start a PIC simulation with positions that
  are chosen to be more evenly spaced than purely random. Indeed, for
  some calculations it is advantageous (but non-physical) to start
  with density fluctuations even <em>lower</em> than the final level
  that would be present for a steady plasma. In either case, what is
  called a "Quiet Start" can be obtained by using what are called
  "quasi-random" numbers [see e.g.&nbsp;<i>Numerical Recipes</i>]
  instead of (pseudo) random numbers. Quasi-random numbers are
  somewhat random, but much smoother in their distribution because
  each new number takes account of the already used numbers and tries
  to avoid being close to them. Successive numbers are thus correlated
  rather than uncorrelated. For Monte-Carlo integration, such smoother
  distributions in space are also often highly appropriate and can
  give lower-noise results for the same number of samples, beating the
  weak, 1/&#8730;N, decrease of fractional error.
</p><p>
<a id="tthFtNtAHE"></a><a href="chap11.html#tthFrefAHE"><sup>74</sup></a>Or if we wish to do
  "quiet injection" that is smoother than purely random
</p><p>
<a id="tthFtNtAHF"></a><a href="chap11.html#tthFrefAHF"><sup>75</sup></a><b>The
    Discrete Poisson distribution.</b> Suppose there is a very large
  number N of similar, uncorrelated, events (for example radioactive
  decays of atoms) waiting to occur. In a time duration far shorter
  than the waiting time (e.g.&nbsp;the half-life) of an individual event
  the probability that any one of them occurs is small, say p = r/N. Then r is the average total number of events occuring in
  this time duration. The total number of events actually occuring in
  a particular time sample is then an integer, and we want to find the
  probability of each possible integer. Any sample consists of N
  choices about the individual events: yes or no. The number of yes
  events is distributed as a Binomial distribution, in which the
  probability of n yes events is given by the number of different
  ways to choose n out of N, which is <br clear="all" /><table border="0" align="left" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap"></td><td nowrap="nowrap" align="center">
N!
<div class="hrcomp"><hr noshade="noshade" size="1"/></div>n! (N&#8722;n)!<br /></td><td nowrap="nowrap" align="center">

</td></tr></table><br />, times
  the probability of each specific arrangement of n yes events and
  N&#8722;n no events, p<sup>n</sup>(1&#8722;p)<sup>N&#8722;n</sup>. The total is

<br clear="all" /><table border="0" width="100%"><tr><td>
<table align="center" cellspacing="0"  cellpadding="2"><tr><td nowrap="nowrap" align="center">
p<sub>n</sub> = </td><td nowrap="nowrap" align="center">
N!
<div class="hrcomp"><hr noshade="noshade" size="1"/></div>n! (N&#8722;n)!<br /></td><td nowrap="nowrap" align="center">
p<sup>n</sup>(1&#8722;p)<sup>N&#8722;n</sup> = </td><td nowrap="nowrap" align="center">
r<sup>n</sup>
<div class="hrcomp"><hr noshade="noshade" size="1"/></div>n!<br /></td><td nowrap="nowrap" align="center">
</td><td align="left" class="cl">&#x239B;<br />&#x239D;
</td><td nowrap="nowrap" align="center">
1&#8722;</td><td nowrap="nowrap" align="center">
r
<div class="hrcomp"><hr noshade="noshade" size="1"/></div>N<br /></td><td align="left" class="cl">&#x239E;<br />&#x23A0;
</td><td nowrap="nowrap" align="center">
<small>N</small><!--sup
--><br /><br />
<small></small>&nbsp;<br /></td><td nowrap="nowrap" align="center">
</td><td align="left" class="cl">&#x23A1;<br />&#x23A3;
</td><td nowrap="nowrap" align="center">
1
<div class="hrcomp"><hr noshade="noshade" size="1"/></div>N<sup>n</sup>(1&#8722;r/ N)<sup>n</sup><br /></td><td nowrap="nowrap" align="center">
</td><td nowrap="nowrap" align="center">
N!
<div class="hrcomp"><hr noshade="noshade" size="1"/></div>(N&#8722;n)!<br /></td><td align="left" class="cl">&#x23A4;<br />&#x23A6;
</td><td nowrap="nowrap" align="center">
.</td></tr></table>
</td></tr></table>

 Now recognize that the limit for large N
  (but constant n) of
  the square bracket term is 1; while the limit of the term  (1&#8722;<sup>r</sup>/<sub>N</sub>)<sup>N</sup> is exp(&#8722;r). Therefore the
  probability of obtaining n total events, of a type that are completely
  uncorrelated (N&#8594; &#8734;),
  when their average rate of occurrence is r is

<br clear="all" /><table border="0" width="100%"><tr><td>
<table align="center" cellspacing="0"  cellpadding="2"><tr><td nowrap="nowrap" align="center">
 p<sub>n</sub> = </td><td nowrap="nowrap" align="center">
r<sup>n</sup>
<div class="hrcomp"><hr noshade="noshade" size="1"/></div>n!<br /></td><td nowrap="nowrap" align="center">
exp(&#8722;r).</td></tr></table>
</td></tr></table>

 This is the discrete Poisson distribution.
</p><p>
<a id="tthFtNtAHG"></a><a href="chap11.html#tthFrefAHG"><sup>76</sup></a>Or double-precision if
  N is very large.
</p><p>
<a id="tthFtNtAHH"></a><a href="chap11.html#tthFrefAHH"><sup>77</sup></a>The random generators I used here are both
  portable. The good generator is the <tt>RANLUX</tt> routine
  described by M. Luscher, <i>Computer Physics Communications</i> 79
  (1994) 100, and F. James, <i>Computer Physics Communications</i>
  79 (1994) 111, used with the lowest luxury level. The bad generator
  is the <tt>RAN1</tt> routine from the first (FORTRAN) edition of
  <i>Numerical Recipes</i> (1989). It was replaced by better
  routines in later editions.
</p><p>
<a id="tthFtNtAHI"></a><a href="chap12.html#tthFrefAHI"><sup>78</sup></a>For photons, the "velocity" should
  be interpreted as a combination of energy (frequency or wavelength)
  and propagation direction, since the particle's speed is always the
  speed of light.
</p><p>
<a id="tthFtNtAHJ"></a><a href="chap12.html#tthFrefAHJ"><sup>79</sup></a>The velocity distribution f<sub>k</sub> in discrete velocity
  bins d<sup>3</sup>v<sub>k</sub> may also be desired. It is given by summing only
  those passages that occur in the velocity bin: <br clear="all" /><table border="0" align="left" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap">f<sub>k</sub>d<sup>3</sup>v<sub>k</sub> = </td><td nowrap="nowrap" align="center">
<small></small><!--sup
--><br /><span class="largerstill">&#8721;<br />
</span><small>v<sub>i</sub> &#8712; d<sup>3</sup>v<sub>k</sub></small>&nbsp;<br /></td><td nowrap="nowrap" align="center">
&#8710;t<sub>i</sub>
</td></tr></table><br />. It will have greater statistical
  uncertainty because of fewer samples per bin.
</p><p>
<a id="tthFtNtAIA"></a><a href="chap13.html#tthFrefAIA"><sup>80</sup></a>One such book with lots of engineering examples is
  Steven C Chapra and Raymond P Canale (2006) (5th Ed, or later)
  "Numerical Methods for Engineers" McGraw-Hill, NY.
</p><p>
<a id="tthFtNtAIB"></a><a href="chap13.html#tthFrefAIB"><sup>81</sup></a>The volume of a
  tetrahedron can be written as a 4&times;4 determinant using the
  cartesian coordinates (x<sub>k</sub>,y<sub>k</sub>,z<sub>k</sub>) of its four corners (k=1,4) as

<br clear="all" /><table border="0" width="100%"><tr><td>
<table align="center" cellspacing="0"  cellpadding="2"><tr><td nowrap="nowrap" align="center">
V = </td><td nowrap="nowrap" align="center">
1
<div class="hrcomp"><hr noshade="noshade" size="1"/></div>6<br /></td><td nowrap="nowrap" align="center">
</td><td align="left" class="cl">&#x23A2;<br />&#x23A2;<br />&#x23A2;<br />&#x23A2;<br />
&#x23A2;<br />&#x23A2;<br />&#x23A2;
</td><td nowrap="nowrap" align="center">
<table class="tabular">
<tr><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
1 </td></tr></table></td><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
x<sub>1</sub> </td></tr></table></td><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
y<sub>1</sub> </td></tr></table></td><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
z<sub>1</sub> </td></tr></table></td></tr>
<tr><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
1 </td></tr></table></td><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
x<sub>2</sub> </td></tr></table></td><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
y<sub>2</sub> </td></tr></table></td><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
z<sub>2</sub> </td></tr></table></td></tr>
<tr><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
1 </td></tr></table></td><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
x<sub>3</sub> </td></tr></table></td><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
y<sub>3</sub> </td></tr></table></td><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
z<sub>3</sub> </td></tr></table></td></tr>
<tr><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
1 </td></tr></table></td><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
x<sub>4</sub> </td></tr></table></td><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
y<sub>4</sub> </td></tr></table></td><td align="center"><table border="0" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap" align="center">
z<sub>4</sub> </td></tr></table></td></tr></table>
</td><td align="left" class="cl">&#x23A2;<br />&#x23A2;<br />&#x23A2;<br />&#x23A2;<br />
&#x23A2;<br />&#x23A2;<br />&#x23A2;
</td><td nowrap="nowrap" align="center">
</td></tr></table>
</td></tr></table>



</p><p>
<a id="tthFtNtAIC"></a><a href="chap13.html#tthFrefAIC"><sup>82</sup></a>These important details are discussed
  in texts devoted to finite elements, such as, Thomas J R Hughes
  (1987) "The Finite Element Method" Prentice Hall, Englewood
  Cliffs, NJ. The classic text on the background mathematical theory
  is, G Strang and G J Fix (1973, 2008) "An Analysis of the Finite
  Element Method", Reissued by Wellesley-Cambridge, Press, USA.
</p><p>
<a id="tthFtNtAID"></a><a href="chap13.html#tthFrefAID"><sup>83</sup></a>Since f is periodic, its value at j=0 is the same
  as at j=N, so the range is equivalent to 1,...,N.
</p><p>
<a id="tthFtNtAIE"></a><a href="chap13.html#tthFrefAIE"><sup>84</sup></a>If N is odd, then
  the highest frequency is obviously (N&#8722;1)/2, but we'll avoid
  reiterating this alternative.
</p><p>
<a id="tthFtNtAIF"></a><a href="chap13.html#tthFrefAIF"><sup>85</sup></a>&#1013; is a small adjustment of the end
  point to avoid it falling on a delta function.
</p><p>
<a id="tthFtNtAIG"></a><a href="chap13.html#tthFrefAIG"><sup>86</sup></a>An
   extensive discussion is given in W H Press et al, "Numerical
   Recipes", chapter 12. Various open source implementations are
   available.
</p><p>
<a id="tthFtNtAIH"></a><a href="chap13.html#tthFrefAIH"><sup>87</sup></a>A non-zero
  <b>x</b><sub>0</sub> can be removed by reexpressing the equation in terms of
  <b>x</b>&#8242;=<b>x</b>&#8722;<b>x</b><sub>0</sub>.
</p><p>
<a id="tthFtNtAII"></a><a href="chap13.html#tthFrefAII"><sup>88</sup></a>The present derivation draws on C P Jackson
  and P C Robinson (1985) "A numerical study of various algorithms
  related to the preconditioned conjugate gradient method",
  International Journal for Numerical Methods in Engineering, Vol 21,
  pp 1315-1338, and G Markham (1990) "Conjugate Gradient Type Methods
for Indefinite, Asymmetric, and Complex Systems" IMA Journal of
Numerical Analysis, Vol 10, pp 155-170.
</p><p>
<a id="tthFtNtAIJ"></a><a href="chap13.html#tthFrefAIJ"><sup>89</sup></a>This is a type of Gramm-Schmidt
  basis-set construction.
</p><p>
<a id="tthFtNtAJA"></a><a href="chap13.html#tthFrefAJA"><sup>90</sup></a>Succinct descriptions of a wide
  range of iterative algorithms are given by R. Barrett, M. Berry,
  T. F. Chan, J. Demmel, J. Donato, J. Dongarra, V. Eijkhout, R. Pozo,
  C. Romine, H. Van der Vorst (1994) "Templates for the Solution of
  Linear Systems: Building Blocks for Iterative Methods" 2nd Edition,
  SIAM, Philadelphia, which is available at
  <a href="http://www.netlib.org/linalg/html_templates/report.html"><tt>http://www.netlib.org/linalg/html_templates/report.html</tt></a>. Open
  source libraries of implementations of Krylov schemes are widely
  available. One of the more comprehensive is "SLATEC" at
  <a href="http://www.netlib.org/slatec/"><tt>http://www.netlib.org/slatec/</tt></a>.
</p><p>
<a id="tthFtNtAJB"></a><a href="chap13.html#tthFrefAJB"><sup>91</sup></a>
  Bi-conjugate gradient iterations are implemented using two residual
  and two search direction vectors requiring just one multiplication
  by <b>A</b> and one by <b>A</b><sup>T</sup> per step in this way:

</p><p>

<table class="tabular">
<tr><td align="left">1 Initialize:</td><td align="left">choose <b>x</b><sub>0</sub>, <b>r</b><sub>0</sub>=<b>b</b>&#8722;<b>A</b><b>x</b><sub>0</sub>,
<b>p</b><sub>0</sub>=<b>r</b><sub>0</sub>, choose <br clear="all" /><table border="0" align="left" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap"></td><td nowrap="nowrap" align="center">
<div class="comp">-<br /></div>
<div class="norm"><b>r</b><br /></div>
<div class="comb">&nbsp;</div>
</td><td nowrap="nowrap" align="center">
<small></small><!--sup
--><br /><small>0</small>&nbsp;<br /></td><td nowrap="nowrap" align="center">

</td></tr></table><br />, <br clear="all" /><table border="0" align="left" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap"></td><td nowrap="nowrap" align="center">
<div class="comp">-<br /></div>
<div class="norm"><b>p</b><br /></div>
<div class="comb">&nbsp;</div>
</td><td nowrap="nowrap" align="center">
<small></small><!--sup
--><br /><small>0</small>&nbsp;<br /></td><td nowrap="nowrap" align="center">
=</td><td nowrap="nowrap" align="center">
<div class="comp">-<br /></div>
<div class="norm"><b>r</b><br /></div>
<div class="comb">&nbsp;</div>
</td><td nowrap="nowrap" align="center">
<small></small><!--sup
--><br /><small>0</small>&nbsp;<br /></td><td nowrap="nowrap" align="center">

</td></tr></table><br />, set k=1.</td></tr>
<tr><td align="left">2 Calculate &#945;:</td><td align="left"><br clear="all" /><table border="0" align="left" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap">&#945;<sub>k&#8722;1</sub>=<b>r</b><sup>T</sup><sub>k&#8722;1</sub></td><td nowrap="nowrap" align="center">
<div class="comp">-<br /></div>
<div class="norm"><b>r</b><br /></div>
<div class="comb">&nbsp;</div>
</td><td nowrap="nowrap" align="center">
<small></small><!--sup
--><br /><small>k&#8722;1</small>&nbsp;<br /></td><td nowrap="nowrap" align="center">
/<b>p</b><sup>T</sup><sub>k&#8722;1</sub><b>A</b></td><td nowrap="nowrap" align="center">
<div class="comp">-<br /></div>
<div class="norm"><b>p</b><br /></div>
<div class="comb">&nbsp;</div>
</td><td nowrap="nowrap" align="center">
<small></small><!--sup
--><br /><small>k&#8722;1</small>&nbsp;<br /></td><td nowrap="nowrap" align="center">

</td></tr></table><br /></td></tr>
<tr><td align="left">3 Update <b>r</b>s, <b>x</b>:</td><td align="left"><b>r</b><sub>k</sub> = <b>r</b><sub>k&#8722;1</sub> &#8722; &#945;<sub>k&#8722;1</sub> <b>A</b><b>p</b><sub>k&#8722;1</sub>,&nbsp;&nbsp;&nbsp;
  <br clear="all" /><table border="0" align="left" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap"></td><td nowrap="nowrap" align="center">
<div class="comp">-<br /></div>
<div class="norm"><b>r</b><br /></div>
<div class="comb">&nbsp;</div>
</td><td nowrap="nowrap" align="center">
<small></small><!--sup
--><br /><small>k</small>&nbsp;<br /></td><td nowrap="nowrap" align="center">
 = </td><td nowrap="nowrap" align="center">
<div class="comp">-<br /></div>
<div class="norm"><b>r</b><br /></div>
<div class="comb">&nbsp;</div>
</td><td nowrap="nowrap" align="center">
<small></small><!--sup
--><br /><small>k&#8722;1</small>&nbsp;<br /></td><td nowrap="nowrap" align="center">
&#8722; &#945;<sub>k&#8722;1</sub> <b>A</b><sup>T</sup></td><td nowrap="nowrap" align="center">
<div class="comp">-<br /></div>
<div class="norm"><b>p</b><br /></div>
<div class="comb">&nbsp;</div>
</td><td nowrap="nowrap" align="center">
<small></small><!--sup
--><br /><small>k&#8722;1</small>&nbsp;<br /></td><td nowrap="nowrap" align="center">

</td></tr></table><br />,</td></tr>
<tr><td align="left"></td><td align="left"><b>x</b><sub>k</sub>=<b>x</b><sub>k&#8722;1</sub> &#8722; &#945;<sub>k&#8722;1</sub> <b>A</b><b>p</b><sub>k&#8722;1</sub>.</td></tr>
<tr><td align="left">4 Calculate &#946;:</td><td align="left"><br clear="all" /><table border="0" align="left" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap">&#946;<sub>k,k&#8722;1</sub>=</td><td nowrap="nowrap" align="center">
<div class="comp">-<br /></div>
<div class="norm"><b>r</b><br /></div>
<div class="comb">&nbsp;</div>
</td><td nowrap="nowrap" align="center">
<small>T</small><!--sup
--><br /><small>k</small>&nbsp;<br /></td><td nowrap="nowrap" align="center">
<b>r</b><sub>k</sub>/</td><td nowrap="nowrap" align="center">
<div class="comp">-<br /></div>
<div class="norm"><b>r</b><br /></div>
<div class="comb">&nbsp;</div>
</td><td nowrap="nowrap" align="center">
<small>T</small><!--sup
--><br /><small>k&#8722;1</small>&nbsp;<br /></td><td nowrap="nowrap" align="center">
<b>r</b><sub>k&#8722;1</sub>.
</td></tr></table><br /></td></tr>
<tr><td align="left">5 Update <b>p</b>s:</td><td align="left"><b>p</b><sub>k</sub>=<b>r</b><sub>k</sub>&#8722;&#946;<sub>k,k&#8722;1</sub><b>p</b><sub>k&#8722;1</sub>&nbsp;&nbsp;&nbsp;
and &nbsp;&nbsp;&nbsp;  <br clear="all" /><table border="0" align="left" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap"> </td><td nowrap="nowrap" align="center">
<div class="comp">-<br /></div>
<div class="norm"><b>p</b><br /></div>
<div class="comb">&nbsp;</div>
</td><td nowrap="nowrap" align="center">
<small></small><!--sup
--><br /><small>k</small>&nbsp;<br /></td><td nowrap="nowrap" align="center">
=</td><td nowrap="nowrap" align="center">
<div class="comp">-<br /></div>
<div class="norm"><b>r</b><br /></div>
<div class="comb">&nbsp;</div>
</td><td nowrap="nowrap" align="center">
<small></small><!--sup
--><br /><small>k</small>&nbsp;<br /></td><td nowrap="nowrap" align="center">
&#8722;&#946;<sub>k,k&#8722;1</sub></td><td nowrap="nowrap" align="center">
<div class="comp">-<br /></div>
<div class="norm"><b>p</b><br /></div>
<div class="comb">&nbsp;</div>
</td><td nowrap="nowrap" align="center">
<small></small><!--sup
--><br /><small>k&#8722;1</small>&nbsp;<br /></td><td nowrap="nowrap" align="center">
.
</td></tr></table><br /></td></tr>
<tr><td align="left">6 Convergence?</td><td align="left">If not converged, increment k and repeat from 2.</td></tr></table>


</p><p>
  The conjugate gradient scheme is the same except no barred
quantities are calculated and unbarred quantities replace them.

</p><p>
<a id="tthFtNtAJC"></a><a href="chap13.html#tthFrefAJC"><sup>92</sup></a>A compact mathematical description is given, for
  example, by Stephen Jardin (2010) "Computational Methods for Plasma
  Physics" CRC press, Taylor and Francis, Boca Raton. Section
  3.7.2.
</p><p>
<a id="tthFtNtAJD"></a><a href="chap13.html#tthFrefAJD"><sup>93</sup></a>The
  number of iterations required to converge to a given accuracy for
  separated eigenvalues is approximately proportional to the square
  root of the matrix condition number. The condition number is the
  ratio of the maximum to the minimum eigenvalue. That is unity for
  the unit matrix because all eigenvalues are 1. For a matrix
  representing an isotropic finite-difference Laplacian, the
  eigenvalues are the squared wave numbers of the spatial Fourier
  modes. The condition number is therefore the sum of the squares of
  the number of mesh points in each dimension. The number of
  iterations required is therefore proportional to the mesh count of
  the largest dimension. That is the same as optimized
  SOR. Finding the optimum relaxation parameter for SOR is relatively
  easy for a rectangular mesh on a cubical domain. Consequently
  un-preconditioned Krylov methods for finite-difference equations in
  simple domains are generally not much faster than SOR. Krylov methods come
  into their own when the matrices are more complicated and optimizing
  SOR is impossible, for example for finite element methods on unstructured
  grids.
</p><p>
<a id="tthFtNtAJE"></a><a href="chap13.html#tthFrefAJE"><sup>94</sup></a>There are some problems in liquids
  where sound waves are important; just a minority.
</p><p>
<a id="tthFtNtAJF"></a><a href="chap13.html#tthFrefAJF"><sup>95</sup></a>This equation arises from substituting
  &#961; = constant into the (sourceless) continuity equation, so
  <br clear="all" /><table border="0" align="left" cellspacing="0" cellpadding="0"><tr><td nowrap="nowrap">0=</td><td nowrap="nowrap" align="center">
&#8706;&#961;
<div class="hrcomp"><hr noshade="noshade" size="1"/></div>&#8706;t<br /></td><td nowrap="nowrap" align="center">
=&#8722;&#8711;.(&#961;<b><i>v</i></b>)
</td></tr></table><br />. If
  &#8711;&#961; is non-zero, so &#8711;.(&#961;<b><i>v</i></b>) is non-zero
  even though &#8711;.<b><i>v</i></b>=0, then the pressure equation
  acquires an additional term.
</p><p>
<a id="tthFtNtAJG"></a><a href="chap13.html#tthFrefAJG"><sup>96</sup></a>See, e.g.&nbsp;J H Ferziger and M Peri&#263; (2002)
  "Computational Methods for Fluid Dynamics" third edition,
  Springer, Berlin.
</p><p>
<a id="tthFtNtAJH"></a><a href="chap13.html#tthFrefAJH"><sup>97</sup></a>See, e.g.&nbsp;S Jardin (2010) op
  cit.
</p><p>
<a id="tthFtNtAJI"></a><a href="chap13.html#tthFrefAJI"><sup>98</sup></a>A comprehensive introduction to limiter
  methods is given in Randall J Leveque (2002) "Finite Volume Methods
  for Hyperbolic Problems", Cambridge University
  Press.
</p><p>
<a id="tthFtNtAJJ"></a><a href="chap13.html#tthFrefAJJ"><sup>99</sup></a>A large
  jet aircraft may reach 10<sup>9</sup>.
</p><p>
<a id="tthFtNtBAA"></a><a href="chap13.html#tthFrefBAA"><sup>100</sup></a>See for example U. Piomelli
  (1999) "Large-eddy simulation: achievements and challenges"
  Progress in Aerospace Sciences, Vol 35, pp 335-362
</p><p>
<a id="tthFtNtBAB"></a><a href="chap13.html#tthFrefBAB"><sup>101</sup></a>or
  the product of two different fluctuating quantities
</p><p>
<a id="tthFtNtBAC"></a><a href="chap13.html#tthFrefBAC"><sup>102</sup></a>See for example B E Launder, G J Reece,
  and W Rodi (1975) "Progress in development of a Reynolds-stress
  turbulence closure", Journal of Fluid Mechanics, Vol 68, pp
  537-566.
</p><p>
<a id="tthFtNtBAD"></a><a href="chapA.html#tthFrefBAD"><sup>103</sup></a>Of course there are deeper ways to think about vector
  spaces, but we here use the simplest approach.
</p><p>
<a id="tthFtNtBAE"></a><a href="chapA.html#tthFrefBAE"><sup>104</sup></a>So a column
  vector can be considered a J&times;1 matrix and a row vector a
  1&times;J matrix.
</p><p>
<a id="tthFtNtBAF"></a><a href="chapA.html#tthFrefBAF"><sup>105</sup></a>Consider recursively expanding the determinant and
  subsequent cofactors, always choosing not to expand by the rows that
  are identical. Eventually one ends up with all 2&times;2 cofactors composed
  of the identical rows. They are all zero.
</p><p>
<a id="tthFtNtBAG"></a><a href="chapA.html#tthFrefBAG"><sup>106</sup></a>A left
  inverse <b>A</b><sup>L</sup> such that <b>A</b><sup>L</sup><b>A</b>=<b>I</b> must always
  be equal to a right inverse <b>A</b><sup>R</sup> such that
  <b>A</b><b>A</b><sup>R</sup>=<b>I</b> because
  <b>A</b><sup>L</sup>=<b>A</b><sup>L</sup><b>I</b>=<b>A</b><sup>L</sup>(<b>A</b><b>A</b><sup>R</sup>) = (<b>A</b><sup>L</sup><b>A</b>)<b>A</b><sup>R</sup>=<b>I</b><b>A</b><sup>R</sup>=<b>A</b><sup>R</sup>.<hr /><a href="index.html">HEAD</a>
<br /><br /><hr /><small>File translated from
T<sub><span class="small">E</span></sub>X
by <a href="http://hutchinson.belmont.ma.us/tth/">
T<sub><span class="small">T</span></sub>H</a>,
version 4.08.<br />On 26 Oct 2015, 14:22.</small>
</html>
